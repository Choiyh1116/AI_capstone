{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMBRnFosQ++KPjmHyxlp4RD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Choiyh1116/AI_capstone/blob/CHOI/Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 "
      ],
      "metadata": {
        "id": "bZ_jOHc1-wjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim #method to compare image \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import numpy as np #calculate \n",
        "import cv2 # to Image loaded\n",
        "import os, sys # to drive mount for Colab\n",
        "from google.colab.patches import cv2_imshow # to show image for Colab\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "lTy0eKVB9y-1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 함수"
      ],
      "metadata": {
        "id": "k3Uk-2K19zre"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "uI8MaGhN1SHT"
      },
      "outputs": [],
      "source": [
        "#driveMount(\"/content/drive/MyDrive/video\")\n",
        "def driveMount(path):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  os.chdir(path)\n",
        "\n",
        "#MSE(Mean Square Error)\n",
        "def mse(x,y): return np.sqrt(((x-y)**2).sum())/(x.shape[0])\n",
        "\n",
        "#video convert image list\n",
        "def video_to_image(vidName)->list:\n",
        "  video = cv2.VideoCapture(vidName) #'' 사이에 사용할 비디오 파일의 경로 및 이름을 넣어주도록 함\n",
        "  \n",
        "  if not video.isOpened():\n",
        "    print(\"Could not Open :\", vidName) ; exit(0)\n",
        "  width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) ; fps = video.get(cv2.CAP_PROP_FPS) ; count = 0 ; list = [] ; threshold = 5 # 아무거나 일단\n",
        "  min, sec = minSec(int(length/round(fps)))\n",
        "  print(\"width :\",width) ; print(\"height :\",height)\n",
        "  print(\"min :\", min) ; print(\"sec :\",sec) ; print(\"fps :\", fps)\n",
        "  \n",
        "  while(video.isOpened()):\n",
        "    ret,image = video.read()\n",
        "    if ret:\n",
        "      if(int(video.get(1)) % round(fps) == 0):\n",
        "\n",
        "         \"\"\"image = cv2_to_Image(image)\n",
        "         hash = average_hash(image)\n",
        "         list.append(hash)\"\"\"#이미지 해쉬로 저장\n",
        "         list.append(image)\n",
        "    else :\n",
        "      break\n",
        "\n",
        "  video.release()\n",
        "  return width,height,list\n",
        "\n",
        "#divide time to min , sec\n",
        "def minSec(time) : \n",
        "  min = int(time // 60) ; sec = time%60\n",
        "  return min, sec\n",
        "\n",
        "def cv2_to_Image(img: np.ndarray) -> Image:\n",
        "    # return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "\n",
        "def image_to_cv2(img: Image) -> np.ndarray:\n",
        "    # return cv2.cvtColor(numpy.array(img), cv2.COLOR_RGB2BGR)\n",
        "    return np.asarray(img)\n",
        "\n",
        "def show_images(list):\n",
        "    for i, img in enumerate(list):\n",
        "        plt.subplot(131+i)\n",
        "        plt.imshow(img/255.0)\n",
        "\n",
        "def calculate_scores(list, ssim=False):\n",
        "    org = list[0]\n",
        "    \n",
        "    for i, img in enumerate(list,start = 1):\n",
        "        min, sec = minSec(i)\n",
        "        mse_score = mse(org.flatten(), img.flatten())\n",
        "        if ssim: \n",
        "            ssim_score = ssim(org, img, multichannel=True)\n",
        "            label = \"min {} sec {}; MSE: {:.4f}, SSIM: {:.4f}\"\n",
        "            \n",
        "            print(label.format(min, sec, mse_score, ssim_score ))\n",
        "            \n",
        "        else:\n",
        "            label = \"min {} sec {}; MSE: {:.4f}\"\n",
        "            print(label.format(min, sec, mse_score))\n",
        "        org = img\n",
        "\n",
        "#Average Hash\n",
        "def average_hash(img):\n",
        "    img = img.convert(\"L\") \n",
        "    img = img.resize((16, 16), Image.ANTIALIAS) \n",
        "    pixel_data = img.getdata() \n",
        "    pixels = np.array(pixel_data) \n",
        "    pixels = pixels.reshape((16, 16)) \n",
        "    avg = pixels.mean() \n",
        "    diff = 1 * (pixels > avg) \n",
        "    return diff\n",
        "\n",
        "# 이진 해시로 변환\n",
        "def np2hash(ahash):\n",
        "    bhash = []\n",
        "    for nl in ahash.tolist():\n",
        "        sl = [str(i) for i in nl]\n",
        "        s2 = \"\".join(sl)\n",
        "        i = int(s2, 2) # 이진수를 정수로 변환하기\n",
        "        bhash.append(\"%04x\" % i)\n",
        "    return \"\".join(bhash)\n",
        "\n",
        "#해밍 거리 계산\n",
        "def hamming_dist(a, b):\n",
        "    aa = a.reshape(1, -1) # 1차원 배열로 변환하기\n",
        "    ab = b.reshape(1, -1)\n",
        "    dist = (aa != ab).sum()\n",
        "    return dist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "lhFyhVS3D-RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driveMount(\"/content/drive/MyDrive/video\")\n",
        "width,height,list = video_to_image(\"test1.mp4\")\n",
        "\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54kzcLDEDR6y",
        "outputId": "b3c5da4f-ab70-49f1-a009-d09a589cd368"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "width : 1728\n",
            "height : 1080\n",
            "min : 2\n",
            "sec : 47\n",
            "fps : 30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(list[1].shape)\n",
        "print(len(list[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dC264-wFG_o",
        "outputId": "2bd70654-5c48-41e5-903e-7954f77ac99f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1080, 1728, 3)\n",
            "1080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "Tu9VGLhdEPGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x  ="
      ],
      "metadata": {
        "id": "Hew1EiL-Nchj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train = list[0].reshape(-1,height,width,1).astype('float32') / 255.\n",
        "\n",
        "print('Training',x_train.shape,x_train.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Nx_CYx4F8O",
        "outputId": "405a8152-59c4-425b-c9c8-20fc28fa3be4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (3, 1080, 1728, 1) 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout\n",
        "\n",
        "model = tf.keras.Sequential([ \n",
        "    tf.keras.layers.Dense(1, input_shape=[2]) \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = 'mse',\n",
        "    optimizer = 'adam',# adaptive moment estimation\n",
        "    metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "3kPiYiBuh9uz"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![노드.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "d8zIlkkQjjrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y = w * x + b"
      ],
      "metadata": {
        "id": "F_vYZ3hql4w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok-XMfc4jCen",
        "outputId": "afd69f0f-1e7c-408e-ffdc-e87e8e69751f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([0,1],[2],epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "SxM-N7SipNqS",
        "outputId": "15ee59ea-1642-439a-985c-17e462d91815"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-e60b45367291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1654\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2\n  y sizes: 1\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    }
  ]
}